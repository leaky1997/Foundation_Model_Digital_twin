{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 dataset测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "from thu_006 import THU_006_classification\n",
    "from types import SimpleNamespace\n",
    "\n",
    "#%% \n",
    "argsTHU_006 = SimpleNamespace()\n",
    "argsTHU_006.data_dir = '/home/user/LQ/B_Signal/Signal_foundation_model/Foundation_Model_Digital_twin/datasets/a_006_THU_pro'\n",
    "\n",
    "datasetthu006 = THU_006_classification(argsTHU_006, 'train')\n",
    "print(datasetthu006.selected_data.shape)\n",
    "# %% 测试dataloader\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 data_provider 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# loading dataset: THU_006_Forecasting\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 20\u001b[0m\n\u001b[1;32m     15\u001b[0m task_data_configs \u001b[38;5;241m=\u001b[39m read_task_data_config(args\u001b[38;5;241m.\u001b[39mtask_data_config_path)\n\u001b[1;32m     16\u001b[0m task_data_configs_list \u001b[38;5;241m=\u001b[39m get_task_data_config_list(\n\u001b[1;32m     17\u001b[0m         task_data_configs, default_batch_size\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mget_train_val_test_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_data_configs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mflag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LQ/B_Signal/Signal_foundation_model/Foundation_Model_Digital_twin/data/data_loader_provider.py:48\u001b[0m, in \u001b[0;36mget_train_val_test_data\u001b[0;34m(args, task_data_config, flag)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_train_val_test_data\u001b[39m(args,task_data_config,flag): \u001b[38;5;66;03m# TODO : add the flag to the function\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m     _ , train_dataloader_list \u001b[38;5;241m=\u001b[39m \u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtask_data_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43mflag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[1;32m     49\u001b[0m     _ , val_dataloader_list \u001b[38;5;241m=\u001b[39m get_data(args,task_data_config,flag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     50\u001b[0m     _ , test_dataloader_list \u001b[38;5;241m=\u001b[39m get_data(args,task_data_config,flag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/LQ/B_Signal/Signal_foundation_model/Foundation_Model_Digital_twin/data/data_loader_provider.py:41\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(args, task_data_config, flag)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# loading dataset:\u001b[39m\u001b[38;5;124m\"\u001b[39m, task_data_name)\n\u001b[1;32m     40\u001b[0m args\u001b[38;5;241m.\u001b[39mdata_dir \u001b[38;5;241m=\u001b[39m task_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_dir\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 41\u001b[0m dataset, data_loader \u001b[38;5;241m=\u001b[39m \u001b[43mget_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_data_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m dataset_list\u001b[38;5;241m.\u001b[39mappend(dataset)\n\u001b[1;32m     43\u001b[0m data_loader_list\u001b[38;5;241m.\u001b[39mappend(data_loader)\n",
      "File \u001b[0;32m~/LQ/B_Signal/Signal_foundation_model/Foundation_Model_Digital_twin/data/data_loader_provider.py:25\u001b[0m, in \u001b[0;36mget_dataloader\u001b[0;34m(args, task_data_name, flag)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_dataloader\u001b[39m(args, task_data_name,flag):\n\u001b[1;32m     24\u001b[0m     dataset_task \u001b[38;5;241m=\u001b[39m DATASET_TASK_CLASS[task_data_name]\n\u001b[0;32m---> 25\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     shuffle \u001b[38;5;241m=\u001b[39m flag \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     27\u001b[0m     dataloader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m     28\u001b[0m         dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[1;32m     29\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[1;32m     30\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[1;32m     31\u001b[0m         num_workers\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mnum_workers\n\u001b[1;32m     32\u001b[0m     )\n",
      "File \u001b[0;32m~/LQ/B_Signal/Signal_foundation_model/Foundation_Model_Digital_twin/data/data_base.py:142\u001b[0m, in \u001b[0;36mForecastingDataset.__init__\u001b[0;34m(self, args, flag)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, args, flag):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflag\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LQ/B_Signal/Signal_foundation_model/Foundation_Model_Digital_twin/data/data_base.py:23\u001b[0m, in \u001b[0;36mBaseDataset.__init__\u001b[0;34m(self, args, flag)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# if isinstance(args.data_dict, dict):\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#     self.load_data(args.data_dict)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data_from_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_splits()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselect_data_based_on_flag()\n",
      "File \u001b[0;32m~/LQ/B_Signal/Signal_foundation_model/Foundation_Model_Digital_twin/data/data_base.py:61\u001b[0m, in \u001b[0;36mBaseDataset.load_data_from_directory\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m label_files:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mload(file_path)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels:\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "from data_loader_provider import get_train_val_test_data\n",
    "from utils.dataset_utils import read_task_data_config,get_task_data_config_list\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "from types import SimpleNamespace\n",
    "# 假设配置文件名为 config.yaml\n",
    "\n",
    "    \n",
    "args = SimpleNamespace()\n",
    "args.task_data_config_path = '/home/user/LQ/B_Signal/Signal_foundation_model/Foundation_Model_Digital_twin/data/task_data_yaml/multi_task.yaml'\n",
    "args.batch_size = 32\n",
    "args.num_workers = 4\n",
    "\n",
    "task_data_configs = read_task_data_config(args.task_data_config_path)\n",
    "task_data_configs_list = get_task_data_config_list(\n",
    "        task_data_configs, default_batch_size=args.batch_size)\n",
    "\n",
    "\n",
    "get_train_val_test_data(args, task_data_configs,flag='train')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LQ_signal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
